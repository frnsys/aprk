<?php include "header.html" ?>

<style>

body { background:#f4e9d9; }
body, a, a:visited { color:#444; border-bottom:1px dotted #444; }
a:hover, b, h3 { color:#3a94ac; }
h4, h5 {
	border-bottom:1px solid rgba(55, 55, 55, 0.5);
}

</style>


	<div class="intro">
		<h1>Operant Conditioning</h1>
		<h3>A potent means of reinforcing and shaping voluntary behavior.</h3>

		<div class="cols cols-2">
			<p>You may have heard of <a href="http://en.wikipedia.org/wiki/Classical_conditioning#Origins">Pavlov's dog</a> - a dog that was trained to drool at the sound of a bell. Pavlov's dog is an example of <b>classical conditioning</b>, where the trained behavior is <em>automatic</em>. That is, the dog automatically drools at the sight of food, and in this experiment that automatic behavior was transferred to the sound of a bell.</p>
			<p>With <b>operant conditioning</b>, we're dealing with <em>voluntary</em> behavior. Operant conditioning involves providing reward structures through <b>reinforcement schedules</b> in order to elicit specific controlled behaviors.</p>
			<p>Operant conditioning is ubiquitous in our society, and it can be incredibly powerful. Some would say dangerously so -- addictions such as gambling addiction are due in part to the nature of such conditioning. But operant conditioning is also used extensively in games (in fact, it may be <a href="http://www.wired.com/magazine/2011/12/ff_cowclicker/all/1">all that's necessary</a>), and is what makes many websites, such as <a href="http://reddit.com/">Reddit</a>, so pleasurable (maybe even addictive!). After becoming familiar with it, you'll notice it how pervasive it is, underlying many of the systems we enjoy using so much.</p>
		</div>
	</div><!-- intro -->

	<h2>Reinforcement vs Punishment</h2>
	<div class="cols cols-2">
		<p><b>Reinforcement</b> is anything that encourages a behavior. Anything that reinforces is a <b>reinforcer</b>. <b>Punishment</b>, on the other hand, is anything that <em>discourages</em> a behavior. Anything that punishes is a <b>punisher</b>.</p>
		<p>Both reinforcers and punishers can be divided into positive and negative. <b>Positive</b> just implies that something is being added or introduced; <b>negative</b> implies that something is being removed.</p>
	</div>
	<div class="cols cols-4">
		<figure>
				<img src="img/operant/fig1.png" />
				<figcaption>
					<h4>Positive Reinforcers</h4>
					<p><b>Positive reinforcers</b> increase the likelihood of a behavior when they are presented. Positive reinforcers can range from candy and ice cream to a pat on the back or a promotion at your job. They are rewards in the traditional sense.</p>
				</figcaption>
			</figure>
			<figure>
				<img src="img/operant/fig2.png" />
				<figcaption>
					<h4>Negative Reinforcers</h4>
					<p><b>Negative reinforcers</b> increase the likelihood of a behavior when they are <em>removed</em>. That is, they are displeasurable, or painful, or otherwise unappealing and undesired - so their removal is a reward. For example, the removing an electric shock would be a negative reinforcer.</p>
				</figcaption>
			</figure>
			<figure>
				<img src="img/operant/fig3.png" />
				<figcaption>
					<h4>Positive Punishers</h4>
					<p><b>Positive punishers</b> decrease the likelihood of a behavior when they are presented. Electric shocks and other physical pain are common positive punishers - but they also include things such as economic sanctions. The introduction of a negative reinforcer would also be considered positive punishment.</p>
				</figcaption>
			</figure>
			<figure>
				<img src="img/operant/fig4.png" />
				<figcaption>
					<h4>Negative Punishers</h4>
					<p><b>Negative punishers</b> decrease the likelihood of a behavior when they are <em>removed</em>. Taking away a child's candy, for example. In other words, negative punishment is the removal of a positive reinforcer. </p>
				</figcaption>
			</figure>
	</div>

	<section>
		<div class="sub-demo">
			<div class="demo-info">
					<h5>The Skinner Box</h5>
					<p>The <b>Skinner Box</b> is the prototypical form of operant conditioning. You have a rat in a box with a lever. The target behavior for reinforcing is lever pressing, and the reinforcement reward is a food pellet.</p>
					<p> In general, the rat presses the lever, and is rewarded with a food pellet. The exact reward conditions depend on the <b>reinforcement schedule</b>, which are described below.</p>

				</div>
				<figure class="side-figure">
					<img src="img/operant/fig5.png" />
					<figcaption>A basic Skinner Box.</figcaption>
				</figure>
		</div>

		<div class="sub-demo">
			<div class="demo-info">
				<h5>Reinforcement Schedules</h5>
				<p>In operant conditioning, there are four basic patterns of reinforcement, known collectively as <b>reinforcement schedules</b>. Each reinforcement schedule has different impacts on response frequency; some are more effective than others.</p>
				<p>Reinforcement schedules can vary in two ways:</p>

				<h6>Interval vs. Ratio</h6>
				<p><b>Interval</b> - Reinforcement is applied at regular intervals (that is, after certain amount of time have passed). For example, reinforcement is applied every 10 minutes. The size of this interval is negatively related to response rate - larger intervals mean lower response rates. However, the magnitude of the reward is positively related; bigger, better rewards mean higher response rates.</p>	
				<p><b>Ratio</b> - Reinforcement is applied according to the subject's responses (that is, after a certain amount of responses). For example, reinforcement is applied every 20 responses. Ratio reinforcement can be very effective, but it is limited by fatigue - and thus limited by the size of the required ratio.</p>	

				<h6>Fixed vs Variable</h6>
				<p><b>Fixed</b> - Reinforcement will occur reliably when an interval or ratio is satisfied. For example, the reinforcement is applied every 20 responses exactly.</p>	
				<p><b>Variable</b> - Reinforcement occurs only at an average of the interval or ratio. For example, the reinforcement is applied, <em>on average</em>, every 20 responses - it could happen at 18 responses, or 22 responses, and so on. This level of unpredicatbility makes variable reinforcement very powerful, as we'll see later.</p>	

				<p>From these we have four combinations of basic reinforcement schedules: <b>fixed interval</b>, <b>fixed ratio</b>, <b>variable interval</b>, and <b>variable ratio</b>. Their effectiveness in eliciting response rate is shown in the accompanying graph.</p>

			</div>
			<figure class="side-figure">
				<img src="img/operant/fig6.png" />
				<figcaption>Response amount by reinforcement schedule type. Each hatch mark designates a reinforcement. Image adapted from <a href="http://en.wikipedia.org/wiki/File:Schedule_of_reinforcement.png">Wikipedia</a>.</figcaption>
					<p>Each reinforcement schedule has different effects on responses:</p>
					<div class="cols cols-3 borders">
						<p><b>Fixed Interval</b> - The response increases rather gradually as the end of the interval approaches. In the Skinner Box, the rat presses the lever at a higher rate as the next reinforcement time approaches.</p>
						<p><b>Variable Interval</b> - The response rate remains steady, at a relatively low rate, since response amount isn't a factor. In the Skinner Box, the rat presses the lever at a relatively flat rate, since it cannot anticipate when the next reinforcement will be.</p>
						<p><b>Fixed Ratio</b> - The response increases rapidly as the required response quota is approached. There's a pause at the beginning of each action-reward cycle; initial responses are known not to cause immediate reward, so there's little incentive to start. This pause varies positively with the size of the ratio - smaller ratios mean shorter pauses. Extremely high ratios can lead to <em>abulia</em>, meaning the reinforced behavior may be extinguished. In the Skinner Box, the rat presses the lever at a higher rate the closer it gets to its required response amount.</p>
						<p><b>Variable Ratio</b> - The response can remain steadily high. Variable ratio schedules with an average ratio equal to the ratio of a fixed ratio schedule are comparatively more powerful. In the Skinner Box, the rat presses the lever at a higher rate as the next reinforcement time approaches.</p>
				</div>
			</figure>
		</div>
	</section>

	<h2>Operant Conditioning in the Real World</h2>
	<div class="cols cols-4">
		<figure>
				<img src="img/operant/fig7.png" />
				<figcaption>
					<p>Operant conditioning is everywhere! One of my favorite examples is video games. Most games can be reduced to Skinner boxes, with core game mechanics being based on simple reinforcement schedules. For example, let's look at  <a href="http://en.wikipedia.org/wiki/World_of_Warcraft">World of Warcraft</a>.</p>
					<p>Not too long ago (and even now still), WoW, as it was known, was a notoriously addictive game. Applying some basic principles of operant conditioning can give us some insight as to why.</p>
				</figcaption>
			</figure>
		<figure>
				<img src="img/operant/fig8.png" />
				<figcaption>
					<p>If you're unfamiliar with the game, here's a brief overview: you have a character who runs around in a virtual world fighting monsters and completing quests. Your character acquires "experience points" by defeating these monsters and completing these quests.</p>
					<p>Once you've acquired enough experience points, your character "levels up", which means they get stronger, and may gain access to new abilities. Your character is also rewarded items for defeating these monsters and completing these quests. These items can make your character even more powerful, among other things. Some items are extremely powerful and thus highly sought after.</p>
				</figcaption>
			</figure>
		<figure>
				<img src="img/operant/fig9.png" />
				<figcaption>
					<p>Here, there are already two apparent reinforcement schedules. Leveling up is a fixed ratio schedule - you must kill a certain amount of monsters or complete a certain amount of quests before you level up again.</p>
					<p>The item system is a variable ratio schedule. You know you can kill monsters and complete quests to get good items, but it's never a set amount.</p>
					<p>You may find yourself caught in the "just one more" loop, where you tell yourself - just one more monster - the next one might drop a good item - and then I'll stop. But then it doesn't, and you don't stop. Because maybe the <em>next</em> one has that good item.</p>
				</figcaption>
			</figure>
		<figure>
				<img src="img/operant/fig10.png" />
				<figcaption>
					<p>I don't mean to say this is <em>all</em> there is to these games. But it seems like (and this is very controversial) that maybe operant conditioning mechanics are all that's necessary to make a successful game. Ian Bogost's <a href="http://www.bogost.com/games/cow_clicker.shtml">Cow Clicker</a> is an infamous example and criticism of this (Wired has a great <a href="http://www.wired.com/magazine/2011/12/ff_cowclicker/all/1">write-up on the game</a>). For more on "behavioral game design", this <a href="http://www.gamasutra.com/view/feature/3085/behavioral_game_design.php?print=1">article at Gamasutra</a> is worth a read.</p>
				</figcaption>
			</figure>
	</div>


	<div class="sources">
		<h4>Sources</h4>
		<ul>
			<li>Hopson, J. (2001, April 27). <a href="http://www.gamasutra.com/view/feature/3085/behavioral_game_design.php?print=1">Behavioral game design</a>. Gamasutra - The Art & Business of Making Games.</li>
			<li>Skinner, B. F. (1978). <a href=" http://www.bfskinner.org/BFSkinner/SurveyOperantBehavior.html">A brief survey of operant behavior.</a></li>
			<li>Skinner, B. F. (2005). <a href="http://www.bfskinner.org/BFSkinner/Society_files/Science_and_Human_Behavior.pdf">Science and human behavior (PDF)</a>.</li>
		</ul>
	</div>



<?php include "footer.html" ?>

<!-- page-specific scripts -->

</body>
</html>

